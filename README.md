### Abstract

Multi Head Latent Attention Uses SVD for matrix compression. Our goal it to implement randomized-SVD instead of SVD, and make the process more efficient.

### Standard SVD Implementation

\href{https://github.com/cangokmen/CS599-Randomized-SVD/blob/master/docs/README(SVD).md}{README(SVD).md}

### How to run?


### acknowledgements
MLA implementation is based on nanoGPT implementation of Karpathy.
https://github.com/karpathy/nanoGPT
